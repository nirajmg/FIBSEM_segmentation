{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "developmental-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import napari\n",
    "import numpy as np\n",
    "import imutils\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from pyMSDtorch.core import helpers, train_scripts, corcoef\n",
    "from pyMSDtorch.core.networks import MSDNet, TUNet\n",
    "\n",
    "import torch.nn as nn\n",
    "from skimage import exposure\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "\n",
    "from tifffile import imread, imwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-emission",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d61f9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "norman-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_training(imgs, masks, seed=123):\n",
    "    x = np.arange(imgs.shape[0])\n",
    "    random.seed(seed)\n",
    "    random.shuffle(x)\n",
    "    \n",
    "    return imgs[x,:], masks[x,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-subscription",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a2ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_data(image,mask):\n",
    "    image,mask = np.array(image),np.array(mask)\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = thresh.astype(np.uint8)\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    for c in cnts:\n",
    "        # compute the center of the contour\n",
    "        M = cv2.moments(c)\n",
    "        \n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "        w = 1700\n",
    "        x = max(0,cX - w/2)\n",
    "        y = max(0,cY - w/2)\n",
    "        if x+w >2000: x = x - (x+w - 2000)\n",
    "        if y+w >2000: y = y - (y+w - 2000)\n",
    "            \n",
    "        return image[int(y):int(y+w), int(x):int(x+w)],mask[int(y):int(y+w), int(x):int(x+w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defensive-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'training_processed_images/combined_nuclie/raw'\n",
    "train_imgs,train_masks,test_imgs,test_masks =[],[],[],[]\n",
    "\n",
    "imgs,masks = imread(datadir + '/train.tif'),imread(datadir + '/masks.tif')\n",
    "for i, img in enumerate(imgs):\n",
    "    cropped_img,cropped_mask = crop_data(imgs[i],masks[i])\n",
    "    train_imgs.append(cropped_img)\n",
    "    train_masks.append(cropped_mask)\n",
    "\n",
    "imgs,masks = imread(datadir + '/test.tif'),imread(datadir + '/test_masks.tif')\n",
    "for i, img in enumerate(imgs):\n",
    "    cropped_img,cropped_mask = crop_data(imgs[i],masks[i])\n",
    "    test_imgs.append(cropped_img)\n",
    "    test_masks.append(cropped_mask)\n",
    "\n",
    "train_imgs,train_masks,test_imgs,test_masks =np.array(train_imgs),np.array(train_masks),np.array(test_imgs),np.array(test_masks) \n",
    "train_imgs = np.expand_dims(train_imgs, axis=1)\n",
    "train_masks = np.expand_dims(train_masks, axis=1)\n",
    "test_imgs = np.expand_dims(test_imgs, axis=1)\n",
    "test_masks = np.expand_dims(test_masks, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gorgeous-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, train_masks = shuffle_training(train_imgs, train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation set\n",
    "num_val = int(0.1*train_imgs.shape[0])\n",
    "\n",
    "print('Number of images for validation: '+ str(num_val))\n",
    "\n",
    "val_imgs = train_imgs[-num_val:,:,:]\n",
    "val_masks = train_masks[-num_val:,:,:]\n",
    "train_imgs = train_imgs[:-num_val,:,:]   # actual training\n",
    "train_masks = train_masks[:-num_val,:,:]   # actual training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-batch",
   "metadata": {},
   "source": [
    "### Verify dimensionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of training data:   ', train_imgs.shape)\n",
    "print('Size of validation data: ', val_imgs.shape)\n",
    "print('Size of testing data:    ', test_imgs.shape)\n",
    "\n",
    "num_labels = np.unique(train_masks[0:5,:])\n",
    "print('The unique mask labels: ', num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "julian-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewer = napari.view_image(train_imgs[::3,:], colormap='gray', name='Input')\n",
    "#viewer.add_labels(train_masks[::3,:], name='Target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-arbitration",
   "metadata": {},
   "source": [
    "### Prep data for PyTorch ingestion with DataLoaders\n",
    "\n",
    "PyTorch dataloaders are popular structures for passing batches of data to GPU\n",
    "\n",
    "- increase batch_size_train to load GPU with more data\n",
    "- with such large images (2000x2000), U-Nets can handle bigger batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "specialized-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loaders(train_data, val_data, test_data, \n",
    "                batch_size_train, batch_size_val, batch_size_test):\n",
    "    # can adjust the batch size depending on available memory\n",
    "    train_loader_params = {'batch_size': batch_size_train,\n",
    "                     'shuffle': True,\n",
    "                     'num_workers': num_workers,\n",
    "                     'pin_memory':True,\n",
    "                     'drop_last': False}\n",
    "\n",
    "    val_loader_params = {'batch_size': batch_size_val,\n",
    "                     'shuffle': False,\n",
    "                     'num_workers': num_workers,\n",
    "                     'pin_memory':True,\n",
    "                     'drop_last': False}\n",
    "\n",
    "    test_loader_params = {'batch_size': batch_size_test,\n",
    "                     'shuffle': False,\n",
    "                     'num_workers': num_workers,\n",
    "                     'pin_memory':True,\n",
    "                     'drop_last': False}\n",
    "\n",
    "    # Finally, train/val/test loaders are created\n",
    "\n",
    "    train_loader = DataLoader(train_data, **train_loader_params)\n",
    "    val_loader = DataLoader(val_data, **val_loader_params)\n",
    "    test_loader = DataLoader(test_data, **test_loader_params)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1c445",
   "metadata": {},
   "source": [
    " Data Augmentation if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_imgs = torch.Tensor(train_imgs)\n",
    "labeled_masks = torch.Tensor(train_masks)\n",
    "# Data augmentation\n",
    "rotated_imgs1 = torch.rot90(labeled_imgs, 1, [2, 3])\n",
    "rotated_masks1 = torch.rot90(labeled_masks, 1, [2, 3])\n",
    "\n",
    "#rotated_imgs2 = torch.rot90(labeled_imgs, 2, [2, 3])\n",
    "#rotated_masks2 = torch.rot90(labeled_masks, 2, [2, 3])\n",
    "\n",
    "#rotated_imgs3 = torch.rot90(labeled_imgs, 3, [2, 3])\n",
    "\n",
    "#rotated_masks3 = torch.rot90(labeled_masks, 3, [2, 3])\n",
    "\n",
    "#flipped_imgs1 = torch.flip(labeled_imgs, [2])\n",
    "#flipped_masks1 = torch.flip(labeled_masks, [2])\n",
    "\n",
    "#flipped_imgs2 = torch.flip(labeled_imgs, [3])\n",
    "#flipped_masks2 = torch.flip(labeled_masks, [3])\n",
    "\n",
    "#flipped_imgs3 = torch.flip(labeled_imgs, [2,3])\n",
    "#flipped_masks3 = torch.flip(labeled_masks, [2,3])\n",
    "\n",
    "\n",
    "labeled_imgs = torch.cat((labeled_imgs, rotated_imgs1),0)\n",
    "labeled_masks = torch.cat((labeled_masks, rotated_masks1),0)\n",
    "\n",
    "#labeled_imgs = torch.cat((labeled_imgs, rotated_imgs2),0)\n",
    "#labeled_masks = torch.cat((labeled_masks, rotated_masks2),0)\n",
    "\n",
    "#labeled_imgs = torch.cat((labeled_imgs, rotated_imgs3),0)\n",
    "#labeled_masks = torch.cat((labeled_masks, rotated_masks3),0)\n",
    "\n",
    "#labeled_imgs = torch.cat((labeled_imgs, flipped_imgs1),0)\n",
    "#labeled_masks = torch.cat((labeled_masks, flipped_masks1),0)\n",
    "\n",
    "#labeled_imgs = torch.cat((labeled_imgs, flipped_imgs2),0)\n",
    "#labeled_masks = torch.cat((labeled_masks, flipped_masks2),0)\n",
    "\n",
    "#labeled_imgs = torch.cat((labeled_imgs, flipped_imgs3),0)\n",
    "#labeled_masks = torch.cat((labeled_masks, flipped_masks3),0)\n",
    "\n",
    "print('Shape of augmented data:    ', labeled_imgs.shape, labeled_masks.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "overall-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data in pytorch Dataset format\n",
    "\n",
    "labeled_imgs = torch.Tensor(train_imgs)\n",
    "labeled_masks = torch.Tensor(train_masks)\n",
    "\n",
    "val_imgs = torch.Tensor(val_imgs)\n",
    "val_masks = torch.Tensor(val_masks)\n",
    "\n",
    "train_data = TensorDataset(torch.Tensor(labeled_imgs), torch.Tensor(labeled_masks))\n",
    "val_data = TensorDataset(torch.Tensor(val_imgs), torch.Tensor(val_masks))\n",
    "test_data = TensorDataset(torch.Tensor(test_imgs))\n",
    "# create data loaders\n",
    "num_workers = 0   # 1 or 2 work better with CPU, 0 best for GPU\n",
    "\n",
    "batch_size_train = 1\n",
    "batch_size_val = 1\n",
    "batch_size_test = 1\n",
    "\n",
    "train_loader, val_loader, test_loader = make_loaders(train_data,\n",
    "                                                    val_data,\n",
    "                                                    test_data,\n",
    "                                                    batch_size_train, \n",
    "                                                     batch_size_val, \n",
    "                                                     batch_size_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-yemen",
   "metadata": {},
   "source": [
    "### Initialize MSDNet and TUNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "feb4192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_channels = 1\n",
    "out_channels = len(num_labels)\n",
    "num_layers = 50             \n",
    "layer_width = 1 \n",
    "max_dilation = 20      \n",
    "activation = nn.ReLU()\n",
    "normalization = nn.BatchNorm2d\n",
    "final_layer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "falling-grass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  5333\n"
     ]
    }
   ],
   "source": [
    "# MSDNet\n",
    "\n",
    "in_channels = 1\n",
    "out_channels = len(num_labels)\n",
    "num_layers = 40          \n",
    "layer_width = 1\n",
    "max_dilation = 15      \n",
    "activation = nn.ReLU()\n",
    "normalization = nn.BatchNorm2d\n",
    "final_layer = None\n",
    "\n",
    "msdnet = MSDNet.MixedScaleDenseNetwork(in_channels = in_channels,\n",
    "                                    out_channels = out_channels, \n",
    "                                    num_layers=num_layers, \n",
    "                                    layer_width=layer_width,\n",
    "                                    max_dilation = max_dilation, \n",
    "                                    activation=activation,\n",
    "                                    normalization=normalization,\n",
    "                                    convolution=nn.Conv2d\n",
    "                                   )\n",
    "\n",
    "print('Number of parameters: ', helpers.count_parameters(msdnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7318817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  9548\n"
     ]
    }
   ],
   "source": [
    "msdnet = MSDNet.MixedScaleDenseNetwork(in_channels = 1,\n",
    "                                out_channels = len(num_labels),\n",
    "                                  num_layers=45,\n",
    "                                  layer_width=None,\n",
    "                                  max_dilation=None,\n",
    "                                  custom_MSDNet=np.array([1, 2, 4, 8, 16,32])\n",
    "                                  )\n",
    "print('Number of parameters: ', helpers.count_parameters(msdnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUNet 3\n",
    "\n",
    "depth = 4\n",
    "base_channels = 64\n",
    "growth_rate = 2\n",
    "hidden_rate = 1\n",
    "\n",
    "tunet3 = TUNet.TUNet(image_shape=(train_imgs.shape[2:4]),\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            depth=depth,\n",
    "            base_channels=base_channels,\n",
    "            #normalization=None,\n",
    "            growth_rate=growth_rate,\n",
    "            hidden_rate=hidden_rate\n",
    "            )\n",
    "\n",
    "print('Number of parameters: ', helpers.count_parameters(tunet3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-franchise",
   "metadata": {},
   "source": [
    "### Train networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = helpers.get_device()\n",
    "device = \"cuda:1\"\n",
    "epochs = 100   # Set number of epochs\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()   # For segmenting >2 classes\n",
    "\n",
    "LEARNING_RATE = 1e-2\n",
    "optimizer_msd = optim.Adam(msdnet.parameters(), lr=LEARNING_RATE)\n",
    "optimizer_tunet3 = optim.Adam(tunet3.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print('Device we will compute on: ', device)   # cuda:0 for GPU. Else, CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "burning-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "newds_path = 'InitialMSDNetVsTUNet_newmasks_Results'\n",
    "if os.path.isdir(newds_path) is False:\n",
    "    os.mkdir(newds_path)\n",
    "    \n",
    "model_msdnet = '/msdnet'\n",
    "model_tunet3 = '/tunet3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-quilt",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train MSDNet\n",
    "\n",
    "msdnet.to(device)   # send network to GPU\n",
    "\n",
    "main_dir = newds_path + model_msdnet\n",
    "if os.path.isdir(main_dir) is False:\n",
    "    os.mkdir(main_dir)\n",
    "    \n",
    "    \n",
    "stepsPerEpoch = np.ceil(train_imgs.shape[0]/batch_size_train)\n",
    "num_steps_down = 2\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_msd,\n",
    "                                 step_size=int(stepsPerEpoch*(epochs/num_steps_down)),\n",
    "                                 gamma = 0.1,verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "msdnet, results = train_scripts.train_segmentation(\n",
    "    msdnet,train_loader, val_loader, epochs, \n",
    "    criterion, optimizer_msd, device,saveevery=3,scheduler=scheduler,savepath=main_dir,show=1)   # training happens here\n",
    "\n",
    "# clear out unnecessary variables from device (GPU) memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "torch.save(msdnet.state_dict(), main_dir + '/net')\n",
    "np.save(main_dir + '/results.npy', results)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "plt.plot(results['Training loss'], linewidth=2, label='training')\n",
    "plt.plot(results['Validation loss'], linewidth=2, label='validation')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('MSDNet with ReLU and BatchNorm')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(main_dir + '/losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-gauge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size_train = 1\n",
    "batch_size_val = 1\n",
    "batch_size_test = 1\n",
    "\n",
    "tunet3.to(device)   # send network to GPU\n",
    "# clear out unnecessary variables from device (GPU) memory\n",
    "#torch.cuda.empty_cache()\n",
    "\n",
    "main_dir = newds_path + model_tunet3\n",
    "if os.path.isdir(main_dir) is False:\n",
    "    os.mkdir(main_dir)\n",
    "\n",
    "stepsPerEpoch = np.ceil(train_imgs.shape[0]/batch_size_train)\n",
    "num_steps_down = 2\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_tunet3,\n",
    "                                 step_size=int(stepsPerEpoch*(epochs/num_steps_down)),\n",
    "                                 gamma = 0.1,verbose=False)\n",
    "\n",
    "\n",
    "tunet3, results = train_scripts.train_segmentation(\n",
    "    tunet3,train_loader, val_loader, epochs, \n",
    "    criterion, optimizer_tunet3, device,saveevery=3,scheduler=scheduler,savepath=main_dir,show=1)   # training happens here\n",
    "\n",
    "# clear out unnecessary variables from device (GPU) memory\n",
    "torch.cuda.empty_cache()\n",
    "    \n",
    "torch.save(tunet3.state_dict(), main_dir + '/net')\n",
    "np.save(main_dir + '/results.npy', results)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "plt.plot(results['Training loss'], linewidth=2, label='training')\n",
    "plt.plot(results['Validation loss'], linewidth=2, label='validation')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('TUnet with ReLU and BatchNorm')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(main_dir + '/losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edda190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'image_shape': train_imgs.shape[2:4], 'in_channels': in_channels, 'out_channels': out_channels, 'depth': depth, 'base_channels': base_channels, 'growth_rate': growth_rate, 'hidden_rate': hidden_rate},\n",
    "np.save(main_dir+'/params.npy',params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-night",
   "metadata": {},
   "source": [
    "### Segment testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "recognized-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_metrics( preds, target):\n",
    "    tmp = corcoef.cc(preds.cpu().flatten(), target.cpu().flatten() )\n",
    "    return(tmp)\n",
    "\n",
    "\n",
    "def segment_imgs(testloader, net):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    seg_imgs = []\n",
    "    noisy_imgs = []\n",
    "    \n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            noisy = batch\n",
    "            noisy = noisy[0]\n",
    "            noisy = torch.FloatTensor(noisy)\n",
    "            noisy = noisy.to(device)#.unsqueeze(1)\n",
    "            output = net(noisy)\n",
    "            # Compute Pearson Correlation\n",
    "            #tmp =  regression_metrics(output, target)\n",
    "            #running_CC_test_val += tmp.item()\n",
    "\n",
    "            if counter == 0:\n",
    "                seg_imgs = output.detach().cpu()\n",
    "                noisy_imgs = noisy.detach().cpu()\n",
    "                #target_imgs = target.detach().cpu()\n",
    "            else:\n",
    "               \n",
    "                seg_imgs = torch.cat((seg_imgs, output.detach().cpu()), 0)\n",
    "                noisy_imgs = torch.cat((noisy_imgs, noisy.detach().cpu()), 0)\n",
    "            counter+=1\n",
    "    torch.cuda.empty_cache()\n",
    "    return seg_imgs, noisy_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "handy-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "msdnet_output, noisy  = segment_imgs(test_loader, msdnet)\n",
    "tunet3_output, noisy  = segment_imgs(test_loader, tunet3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "awful-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "msdnet_output = torch.argmax(msdnet_output.cpu()[:,:,:,:].data, dim=1)\n",
    "tunet3_output = torch.argmax(tunet3_output.cpu()[:,:,:,:].data, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msdnet_output.size())\n",
    "print(tunet3_output.size())\n",
    "noisy = torch.squeeze(noisy,1)\n",
    "print(noisy.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "growing-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "imwrite(newds_path + '/msdnet_output.tif', msdnet_output.numpy())\n",
    "imwrite(newds_path + '/tunet3_output.tif', tunet3_output.numpy())\n",
    "imwrite(newds_path + '/input.tif', noisy.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-program",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(msdnet.state_dict(), newds_path + '/msdnet')\n",
    "torch.save(tunet3.state_dict(), newds_path + '/tunet3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(noisy.cpu().numpy(), colormap='gray', name='Input')\n",
    "viewer.add_labels(msdnet_output.numpy(), name='msdnet')\n",
    "viewer.add_labels(tunet3_output.numpy(), name='tunet3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
